{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac48f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import ray\n",
    "\n",
    "#ray.shutdown()\n",
    "#ray.init(object_store_memory=4000000000) # set object store memory to 4GB\n",
    "\n",
    "data = pd.read_pickle('C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\data\\\\pickle_files\\\\full_dataset.pkl')\n",
    "sample = data.sample(101, random_state=1)\n",
    "\n",
    "# tansform 'Rating' from Categorical to float\n",
    "import numpy as np\n",
    "sample[\"Rating\"] = pd.to_numeric(sample[\"Rating\"], errors='coerce')\n",
    "\n",
    "# drop all rows with inf/-inf values!\n",
    "import numpy as np\n",
    "sample = sample[(sample != np.inf).all(axis=1)]\n",
    "sample = sample[(sample != -np.inf).all(axis=1)]\n",
    "\n",
    "#get rid of whitespace to draw tree later\n",
    "Eq_Stylebox = sample['Eq_Stylebox_Long'].astype('object').replace(' ','_', regex=True)\n",
    "sample['Eq_Stylebox_Long'] = Eq_Stylebox.astype('category')\n",
    "\n",
    "# shifting target variable to predict next month\n",
    "sample['returns'] = sample.returns.shift(-1)\n",
    "sample = sample.drop(sample.tail(1).index)\n",
    "\n",
    "\n",
    "X = sample.drop('returns', axis=1)\n",
    "y = sample['returns']\n",
    "\n",
    "# create dummies in case of categorical data\n",
    "dummy_needed = [#'Rating',\n",
    "                'Financial_Health_Grade_Long',\n",
    "                 'Growth_Grade_Long',\n",
    "                 'Profitability_Grade_Long',\n",
    "                 'Eq_Stylebox_Long']\n",
    "\n",
    "X = pd.get_dummies(X, columns=dummy_needed)\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 26)\n",
    "X_train = ray.put(X_train)\n",
    "y_train = ray.put(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f59d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-15 15:42:50</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:11.61        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.2/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: -0.0768838371649094<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/3.48 GiB heap, 0.0/1.74 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     rmse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_ad4f1e53</td><td>TERMINATED</td><td>127.0.0.1:10492</td><td style=\"text-align: right;\">           0.902712</td><td style=\"text-align: right;\">          0.882288</td><td style=\"text-align: right;\">    0.0154484  </td><td style=\"text-align: right;\">         15</td><td style=\"text-align: right;\">          9165</td><td style=\"text-align: right;\">  0.0234017</td><td style=\"text-align: right;\">  0.347261  </td><td style=\"text-align: right;\">   0.692471</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        345.425 </td><td style=\"text-align: right;\">0.073901 </td></tr>\n",
       "<tr><td>objective_ca631938</td><td>TERMINATED</td><td>127.0.0.1:25188</td><td style=\"text-align: right;\">           0.541357</td><td style=\"text-align: right;\">          0.596886</td><td style=\"text-align: right;\">    0.0641761  </td><td style=\"text-align: right;\">         13</td><td style=\"text-align: right;\">          8163</td><td style=\"text-align: right;\">  0.0421794</td><td style=\"text-align: right;\">  0.00963603</td><td style=\"text-align: right;\">   0.519678</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        259.451 </td><td style=\"text-align: right;\">0.0722878</td></tr>\n",
       "<tr><td>objective_afdda564</td><td>TERMINATED</td><td>127.0.0.1:848  </td><td style=\"text-align: right;\">           0.937159</td><td style=\"text-align: right;\">          0.74655 </td><td style=\"text-align: right;\">    0.00424176 </td><td style=\"text-align: right;\">         13</td><td style=\"text-align: right;\">          7821</td><td style=\"text-align: right;\">  0.0668953</td><td style=\"text-align: right;\">  0.428247  </td><td style=\"text-align: right;\">   0.562704</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        342.288 </td><td style=\"text-align: right;\">0.0763822</td></tr>\n",
       "<tr><td>objective_ee584a15</td><td>TERMINATED</td><td>127.0.0.1:23908</td><td style=\"text-align: right;\">           0.818962</td><td style=\"text-align: right;\">          0.774141</td><td style=\"text-align: right;\">    0.134671   </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          3289</td><td style=\"text-align: right;\">  2.4944   </td><td style=\"text-align: right;\">  3.0427    </td><td style=\"text-align: right;\">   0.560885</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        119.963 </td><td style=\"text-align: right;\">0.0847576</td></tr>\n",
       "<tr><td>objective_e2eaabe7</td><td>TERMINATED</td><td>127.0.0.1:20920</td><td style=\"text-align: right;\">           0.609467</td><td style=\"text-align: right;\">          0.955516</td><td style=\"text-align: right;\">    0.566614   </td><td style=\"text-align: right;\">         15</td><td style=\"text-align: right;\">          3181</td><td style=\"text-align: right;\">  0.0490848</td><td style=\"text-align: right;\">  0.0644648 </td><td style=\"text-align: right;\">   0.996643</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        135.22  </td><td style=\"text-align: right;\">0.085354 </td></tr>\n",
       "<tr><td>objective_802a56aa</td><td>TERMINATED</td><td>127.0.0.1:18644</td><td style=\"text-align: right;\">           0.730399</td><td style=\"text-align: right;\">          0.976417</td><td style=\"text-align: right;\">    0.000221709</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          2039</td><td style=\"text-align: right;\">  0.0660934</td><td style=\"text-align: right;\">  0.923034  </td><td style=\"text-align: right;\">   0.763139</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        101.107 </td><td style=\"text-align: right;\">0.326005 </td></tr>\n",
       "<tr><td>objective_e736bb43</td><td>TERMINATED</td><td>127.0.0.1:13560</td><td style=\"text-align: right;\">           0.580753</td><td style=\"text-align: right;\">          0.832107</td><td style=\"text-align: right;\">    0.00527648 </td><td style=\"text-align: right;\">         13</td><td style=\"text-align: right;\">           205</td><td style=\"text-align: right;\">  0.663401 </td><td style=\"text-align: right;\">  1.85486   </td><td style=\"text-align: right;\">   0.587036</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         11.6203</td><td style=\"text-align: right;\">0.201903 </td></tr>\n",
       "<tr><td>objective_94c09676</td><td>TERMINATED</td><td>127.0.0.1:27196</td><td style=\"text-align: right;\">           0.674752</td><td style=\"text-align: right;\">          0.984202</td><td style=\"text-align: right;\">    0.132633   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2104</td><td style=\"text-align: right;\"> 14.7836   </td><td style=\"text-align: right;\">  0.111044  </td><td style=\"text-align: right;\">   0.503131</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         82.0164</td><td style=\"text-align: right;\">0.375419 </td></tr>\n",
       "<tr><td>objective_cfcc10d8</td><td>TERMINATED</td><td>127.0.0.1:13560</td><td style=\"text-align: right;\">           0.710373</td><td style=\"text-align: right;\">          0.746098</td><td style=\"text-align: right;\">    0.720728   </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">          1266</td><td style=\"text-align: right;\">  3.85328  </td><td style=\"text-align: right;\"> 13.6576    </td><td style=\"text-align: right;\">   0.736518</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         48.1262</td><td style=\"text-align: right;\">0.0957862</td></tr>\n",
       "<tr><td>objective_1621e9ec</td><td>TERMINATED</td><td>127.0.0.1:23908</td><td style=\"text-align: right;\">           0.979622</td><td style=\"text-align: right;\">          0.859535</td><td style=\"text-align: right;\">    0.00496481 </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">          6742</td><td style=\"text-align: right;\">  0.676663 </td><td style=\"text-align: right;\">  0.861143  </td><td style=\"text-align: right;\">   0.826328</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        271.226 </td><td style=\"text-align: right;\">0.0783887</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 15:42:50,365\tINFO tune.py:798 -- Total run time: 431.69 seconds (430.53 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.0641761205151982, 'max_depth': 13, 'n_estimators': 8163, 'subsample': 0.5196778239740971, 'colsample_bytree': 0.5968863389387559, 'colsample_bylevel': 0.5413571078215881, 'reg_alpha': 0.04217937137803759, 'reg_lambda': 0.009636032866639773}\n",
      "Wall time: 7min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.0001), np.log(0.9)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", range(1, 16)),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", range(100, 10000)),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"colsample_bylevel\": hp.uniform(\"colsample_bylevel\", 0.5, 1),\n",
    "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(100)),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(100)),\n",
    "}\n",
    "\n",
    "\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=26)\n",
    "\n",
    "# Define the objective function to optimize\n",
    "def objective(config):\n",
    "    model = xgb.XGBRegressor(**config, n_jobs=-1)\n",
    "    score = cross_val_score(model, X=ray.get(X_train), y=ray.get(y_train), scoring=\"neg_mean_squared_error\", cv=kfolds)\n",
    "    rmse = np.sqrt(-np.mean(score))\n",
    "    tune.report(rmse=rmse)\n",
    "\n",
    "# Define the search algorithm\n",
    "search_alg = HyperOptSearch(space=search_space, metric=\"rmse\", mode=\"min\")\n",
    "# to limit number of cores, uncomment and set max_concurrent \n",
    "# algo = ConcurrencyLimiter(algo, max_concurrent=10)\n",
    "scheduler = AsyncHyperBandScheduler()\n",
    "\n",
    "# Define the hyperparameter tuning trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Define the configuration for Ray Tune\n",
    "config = {\n",
    "    'num_samples': 10,\n",
    "    'config': search_space,\n",
    "    'search_alg': search_alg,\n",
    "    'scheduler': scheduler,\n",
    "    'resources_per_trial': {'cpu': 1},\n",
    "    'metric': 'rmse',\n",
    "    'mode': 'min',\n",
    "    'verbose': 1,\n",
    "    'name': 'xgboost_tuning',\n",
    "    'stop': {'training_iteration': 10},\n",
    "    'local_dir': './ray_results',\n",
    "}\n",
    "\n",
    "# Start the hyperparameter tuning using Ray Tune\n",
    "analysis = tune.run(objective, **config)\n",
    "\n",
    "# Print the best hyperparameters found during the search\n",
    "best_params = analysis.get_best_config(metric='rmse')\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fcce4",
   "metadata": {},
   "source": [
    "### Distributed Ray XGB\n",
    "https://github.com/ray-project/xgboost_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f954f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from ray import tune\n",
    "\n",
    "def train_xgboost(config, checkpoint_dir=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_set = RayDMatrix(X_train, y_train)\n",
    "    test_set = RayDMatrix(X_test, y_test)\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    # train the model\n",
    "    bst = train(\n",
    "        params=config,\n",
    "        dtrain=train_set,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(test_set, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "        num_boost_round=5, #equivalent to 'epochs'\n",
    "        ray_params=RayParams(num_actors=4, cpus_per_actor=2)) #parameters for parallelism\n",
    "    \n",
    "    model_path = 'model.xgb'\n",
    "    bst.save_model(model_path)\n",
    "    print(f'total time taken: {time.time()-start_time}')\n",
    "    print('Final rmse: {:.4f}'.format(\n",
    "    evals_result[\"eval\"][\"rmse\"][-1]))\n",
    "    \n",
    "    return bst\n",
    "    \n",
    "\n",
    "# Define the search algorithm and scheduler\n",
    "#### NOT SURE IF NEEDED OR SUPPORTED IN XGB_RAY! maybe uncomment here and in config\n",
    "search_alg = HyperOptSearch()\n",
    "scheduler = ASHAScheduler(max_t=10, grace_period=1)\n",
    "\n",
    "# Specify the hyperparameter search space.\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"reg:squarederror\", # Use regression objective\n",
    "    \"eval_metric\": \"rmse\", # Set the evaluation metric to RMSE\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 0.9),\n",
    "    \"subsample\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bytree\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bylevel\": tune.uniform(0.8, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 16),\n",
    "    \"n_estimators\": tune.randint(500, 10000),\n",
    "    \"reg_alpha\": tune.loguniform(1e-3, 100),\n",
    "    \"reg_lambda\": tune.loguniform(1e-3, 100),\n",
    "}\n",
    "\n",
    "# Run the hyperparameter search\n",
    "analysis = tune.run(\n",
    "    train_xgboost,\n",
    "    resources_per_trial=RayParams(num_actors=4, cpus_per_actor=2).get_tune_resources(),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    search_alg=search_alg,\n",
    "    scheduler=scheduler,\n",
    "    metric='rmse',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_RMSE = analysis.best_result[\"rmse\"]\n",
    "print(f'Best model parameters: {analysis.best_config}')\n",
    "print(f'Best RMSE: {best_RMSE}')\n",
    "print(analysis.best_config)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb1d6096",
   "metadata": {},
   "source": [
    "sample.to_pickle('sample.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
