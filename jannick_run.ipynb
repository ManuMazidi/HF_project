{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import ray\n",
    "\n",
    "#ray.shutdown()\n",
    "#ray.init(object_store_memory=4000000000) # set object store memory to 4GB\n",
    "\n",
    "sample = pd.read_pickle('./sample.pkl')\n",
    "\n",
    "\n",
    "# tansform 'Rating' from Categorical to float\n",
    "import numpy as np\n",
    "sample[\"Rating\"] = pd.to_numeric(sample[\"Rating\"], errors='coerce')\n",
    "\n",
    "# drop all rows with inf/-inf values!\n",
    "import numpy as np\n",
    "sample = sample[(sample != np.inf).all(axis=1)]\n",
    "sample = sample[(sample != -np.inf).all(axis=1)]\n",
    "\n",
    "#get rid of whitespace to draw tree later\n",
    "Eq_Stylebox = sample['Eq_Stylebox_Long'].astype('object').replace(' ','_', regex=True)\n",
    "sample['Eq_Stylebox_Long'] = Eq_Stylebox.astype('category')\n",
    "\n",
    "# shifting target variable to predict next month\n",
    "sample['returns'] = sample.returns.shift(-1)\n",
    "sample = sample.drop(sample.tail(1).index)\n",
    "\n",
    "\n",
    "X = sample.drop('returns', axis=1)\n",
    "y = sample['returns']\n",
    "\n",
    "# create dummies in case of categorical data\n",
    "dummy_needed = [#'Rating',\n",
    "                'Financial_Health_Grade_Long',\n",
    "                 'Growth_Grade_Long',\n",
    "                 'Profitability_Grade_Long',\n",
    "                 'Eq_Stylebox_Long']\n",
    "\n",
    "X = pd.get_dummies(X, columns=dummy_needed)\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 26)\n",
    "X_train = ray.put(X_train)\n",
    "y_train = ray.put(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca3672",
   "metadata": {},
   "source": [
    "### Distributed Ray XGB\n",
    "https://github.com/ray-project/xgboost_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from ray import tune\n",
    "\n",
    "def train_xgboost(config, checkpoint_dir=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_set = RayDMatrix(X_train, y_train)\n",
    "    test_set = RayDMatrix(X_test, y_test)\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    # train the model\n",
    "    bst = train(\n",
    "        params=config,\n",
    "        dtrain=train_set,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(test_set, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "        num_boost_round=5, #equivalent to 'epochs'\n",
    "        ray_params=RayParams(num_actors=4, cpus_per_actor=2)) #parameters for parallelism\n",
    "    \n",
    "    model_path = 'model.xgb'\n",
    "    bst.save_model(model_path)\n",
    "    print(f'total time taken: {time.time()-start_time}')\n",
    "    print('Final rmse: {:.4f}'.format(\n",
    "    evals_result[\"eval\"][\"rmse\"][-1]))\n",
    "    \n",
    "    return bst\n",
    "    \n",
    "\n",
    "# Define the search algorithm and scheduler\n",
    "#### NOT SURE IF NEEDED OR SUPPORTED IN XGB_RAY! maybe uncomment here and in config\n",
    "search_alg = HyperOptSearch()\n",
    "scheduler = ASHAScheduler(max_t=10, grace_period=1)\n",
    "\n",
    "# Specify the hyperparameter search space.\n",
    "config = {\n",
    "    \"tree_method\": \"approx\", # if access to GPU, set to 'gpu_hist'\n",
    "    \"objective\": \"reg:squarederror\", \n",
    "    \"eval_metric\": \"rmse\", \n",
    "    \"learning_rate\": tune.loguniform(1e-4, 0.9),\n",
    "    \"subsample\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bytree\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bylevel\": tune.uniform(0.8, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 16),\n",
    "    \"n_estimators\": tune.randint(500, 10000),\n",
    "    \"reg_alpha\": tune.loguniform(1e-3, 100),\n",
    "    \"reg_lambda\": tune.loguniform(1e-3, 100),\n",
    "}\n",
    "\n",
    "# Run the hyperparameter search\n",
    "analysis = tune.run(\n",
    "    train_xgboost,\n",
    "    resources_per_trial=RayParams(num_actors=4, cpus_per_actor=2).get_tune_resources(),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    search_alg=search_alg,\n",
    "    scheduler=scheduler,\n",
    "    metric='rmse',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_RMSE = analysis.best_result[\"rmse\"]\n",
    "print(f'Best model parameters: {analysis.best_config}')\n",
    "print(f'Best RMSE: {best_RMSE}')\n",
    "print(analysis.best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
