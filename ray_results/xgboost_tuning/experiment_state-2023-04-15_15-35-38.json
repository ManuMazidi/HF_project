{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"ad4f1e53\",\n  \"config\": {\n    \"learning_rate\": 0.015448449914487915,\n    \"max_depth\": 15,\n    \"n_estimators\": 9165,\n    \"subsample\": 0.6924713073859511,\n    \"colsample_bytree\": 0.8822884542465372,\n    \"colsample_bylevel\": 0.9027120178054613,\n    \"reg_alpha\": 0.02340170275431364,\n    \"reg_lambda\": 0.3472609559445743\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.9027120178054613,\n    \"colsample_bytree\": 0.8822884542465372,\n    \"learning_rate\": 0.015448449914487915,\n    \"max_depth\": 15,\n    \"n_estimators\": 9165,\n    \"reg_alpha\": 0.02340170275431364,\n    \"reg_lambda\": 0.3472609559445743,\n    \"subsample\": 0.6924713073859511\n  },\n  \"experiment_tag\": \"1_colsample_bylevel=0.9027,colsample_bytree=0.8823,learning_rate=0.0154,max_depth=15,n_estimators=9165,reg_alpha=0.0234,reg_lambda=0.3473,subsample=0.6925\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.07390096889271318,\n    \"time_this_iter_s\": 345.42534375190735,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ad4f1e53\",\n    \"experiment_id\": \"622c1c3fb7dc441eb76f187838bdd5c5\",\n    \"date\": \"2023-04-15_15-41-35\",\n    \"timestamp\": 1681566095,\n    \"time_total_s\": 345.42534375190735,\n    \"pid\": 10492,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.015448449914487915,\n      \"max_depth\": 15,\n      \"n_estimators\": 9165,\n      \"subsample\": 0.6924713073859511,\n      \"colsample_bytree\": 0.8822884542465372,\n      \"colsample_bylevel\": 0.9027120178054613,\n      \"reg_alpha\": 0.02340170275431364,\n      \"reg_lambda\": 0.3472609559445743\n    },\n    \"time_since_restore\": 345.42534375190735,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.01707291603088379,\n    \"experiment_tag\": \"1_colsample_bylevel=0.9027,colsample_bytree=0.8823,learning_rate=0.0154,max_depth=15,n_estimators=9165,reg_alpha=0.0234,reg_lambda=0.3473,subsample=0.6925\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681566095.985051,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.07390096889271318,\n      \"min\": 0.07390096889271318,\n      \"avg\": 0.07390096889271318,\n      \"last\": 0.07390096889271318,\n      \"last-5-avg\": 0.07390096889271318,\n      \"last-10-avg\": 0.07390096889271318\n    },\n    \"time_this_iter_s\": {\n      \"max\": 345.42534375190735,\n      \"min\": 345.42534375190735,\n      \"avg\": 345.42534375190735,\n      \"last\": 345.42534375190735,\n      \"last-5-avg\": 345.42534375190735,\n      \"last-10-avg\": 345.42534375190735\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 345.42534375190735,\n      \"min\": 345.42534375190735,\n      \"avg\": 345.42534375190735,\n      \"last\": 345.42534375190735,\n      \"last-5-avg\": 345.42534375190735,\n      \"last-10-avg\": 345.42534375190735\n    },\n    \"time_since_restore\": {\n      \"max\": 345.42534375190735,\n      \"min\": 345.42534375190735,\n      \"avg\": 345.42534375190735,\n      \"last\": 345.42534375190735,\n      \"last-5-avg\": 345.42534375190735,\n      \"last-10-avg\": 345.42534375190735\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.01707291603088379,\n      \"min\": 0.01707291603088379,\n      \"avg\": 0.01707291603088379,\n      \"last\": 0.01707291603088379,\n      \"last-5-avg\": 0.01707291603088379,\n      \"last-10-avg\": 0.01707291603088379\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085b7389842cebb23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085b7389842cebb23f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407596ce35400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407596ce35400000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407596ce35400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407596ce35400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407596ce35400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407596ce35400000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f917b9000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f917b9000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565742.672398,\n  \"relative_logdir\": \"objective_ad4f1e53_1_colsample_bylevel=0.9027,colsample_bytree=0.8823,learning_rate=0.0154,max_depth=15,n_estimators=9165,reg_alph_2023-04-15_15-35-42\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"afdda564\",\n  \"config\": {\n    \"learning_rate\": 0.004241759758447204,\n    \"max_depth\": 13,\n    \"n_estimators\": 7821,\n    \"subsample\": 0.5627043841368018,\n    \"colsample_bytree\": 0.7465500620233985,\n    \"colsample_bylevel\": 0.9371588159249726,\n    \"reg_alpha\": 0.06689530242537192,\n    \"reg_lambda\": 0.4282469233325265\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.9371588159249726,\n    \"colsample_bytree\": 0.7465500620233985,\n    \"learning_rate\": 0.004241759758447204,\n    \"max_depth\": 13,\n    \"n_estimators\": 7821,\n    \"reg_alpha\": 0.06689530242537192,\n    \"reg_lambda\": 0.4282469233325265,\n    \"subsample\": 0.5627043841368018\n  },\n  \"experiment_tag\": \"3_colsample_bylevel=0.9372,colsample_bytree=0.7466,learning_rate=0.0042,max_depth=13,n_estimators=7821,reg_alpha=0.0669,reg_lambda=0.4282,subsample=0.5627\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.07638222004969987,\n    \"time_this_iter_s\": 342.28795862197876,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"afdda564\",\n    \"experiment_id\": \"451199f6383e4d36909886556305d1a4\",\n    \"date\": \"2023-04-15_15-41-50\",\n    \"timestamp\": 1681566110,\n    \"time_total_s\": 342.28795862197876,\n    \"pid\": 848,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.004241759758447204,\n      \"max_depth\": 13,\n      \"n_estimators\": 7821,\n      \"subsample\": 0.5627043841368018,\n      \"colsample_bytree\": 0.7465500620233985,\n      \"colsample_bylevel\": 0.9371588159249726,\n      \"reg_alpha\": 0.06689530242537192,\n      \"reg_lambda\": 0.4282469233325265\n    },\n    \"time_since_restore\": 342.28795862197876,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.01593327522277832,\n    \"experiment_tag\": \"3_colsample_bylevel=0.9372,colsample_bytree=0.7466,learning_rate=0.0042,max_depth=13,n_estimators=7821,reg_alpha=0.0669,reg_lambda=0.4282,subsample=0.5627\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681566110.1613266,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.07638222004969987,\n      \"min\": 0.07638222004969987,\n      \"avg\": 0.07638222004969987,\n      \"last\": 0.07638222004969987,\n      \"last-5-avg\": 0.07638222004969987,\n      \"last-10-avg\": 0.07638222004969987\n    },\n    \"time_this_iter_s\": {\n      \"max\": 342.28795862197876,\n      \"min\": 342.28795862197876,\n      \"avg\": 342.28795862197876,\n      \"last\": 342.28795862197876,\n      \"last-5-avg\": 342.28795862197876,\n      \"last-10-avg\": 342.28795862197876\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 342.28795862197876,\n      \"min\": 342.28795862197876,\n      \"avg\": 342.28795862197876,\n      \"last\": 342.28795862197876,\n      \"last-5-avg\": 342.28795862197876,\n      \"last-10-avg\": 342.28795862197876\n    },\n    \"time_since_restore\": {\n      \"max\": 342.28795862197876,\n      \"min\": 342.28795862197876,\n      \"avg\": 342.28795862197876,\n      \"last\": 342.28795862197876,\n      \"last-5-avg\": 342.28795862197876,\n      \"last-10-avg\": 342.28795862197876\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.01593327522277832,\n      \"min\": 0.01593327522277832,\n      \"avg\": 0.01593327522277832,\n      \"last\": 0.01593327522277832,\n      \"last-5-avg\": 0.01593327522277832,\n      \"last-10-avg\": 0.01593327522277832\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430879fd1b01c98db33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430879fd1b01c98db33f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075649b7a800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075649b7a800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075649b7a800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075649b7a800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474075649b7a800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474075649b7a800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f9050d000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f9050d000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565762.0750475,\n  \"relative_logdir\": \"objective_afdda564_3_colsample_bylevel=0.9372,colsample_bytree=0.7466,learning_rate=0.0042,max_depth=13,n_estimators=7821,reg_alph_2023-04-15_15-36-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"ca631938\",\n  \"config\": {\n    \"learning_rate\": 0.0641761205151982,\n    \"max_depth\": 13,\n    \"n_estimators\": 8163,\n    \"subsample\": 0.5196778239740971,\n    \"colsample_bytree\": 0.5968863389387559,\n    \"colsample_bylevel\": 0.5413571078215881,\n    \"reg_alpha\": 0.04217937137803759,\n    \"reg_lambda\": 0.009636032866639773\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.5413571078215881,\n    \"colsample_bytree\": 0.5968863389387559,\n    \"learning_rate\": 0.0641761205151982,\n    \"max_depth\": 13,\n    \"n_estimators\": 8163,\n    \"reg_alpha\": 0.04217937137803759,\n    \"reg_lambda\": 0.009636032866639773,\n    \"subsample\": 0.5196778239740971\n  },\n  \"experiment_tag\": \"2_colsample_bylevel=0.5414,colsample_bytree=0.5969,learning_rate=0.0642,max_depth=13,n_estimators=8163,reg_alpha=0.0422,reg_lambda=0.0096,subsample=0.5197\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.0722877648951469,\n    \"time_this_iter_s\": 259.4514570236206,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ca631938\",\n    \"experiment_id\": \"a81e0d5d7dc0470db3334fe995be9a43\",\n    \"date\": \"2023-04-15_15-40-18\",\n    \"timestamp\": 1681566018,\n    \"time_total_s\": 259.4514570236206,\n    \"pid\": 25188,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.0641761205151982,\n      \"max_depth\": 13,\n      \"n_estimators\": 8163,\n      \"subsample\": 0.5196778239740971,\n      \"colsample_bytree\": 0.5968863389387559,\n      \"colsample_bylevel\": 0.5413571078215881,\n      \"reg_alpha\": 0.04217937137803759,\n      \"reg_lambda\": 0.009636032866639773\n    },\n    \"time_since_restore\": 259.4514570236206,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.01539921760559082,\n    \"experiment_tag\": \"2_colsample_bylevel=0.5414,colsample_bytree=0.5969,learning_rate=0.0642,max_depth=13,n_estimators=8163,reg_alpha=0.0422,reg_lambda=0.0096,subsample=0.5197\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681566018.7440352,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.0722877648951469,\n      \"min\": 0.0722877648951469,\n      \"avg\": 0.0722877648951469,\n      \"last\": 0.0722877648951469,\n      \"last-5-avg\": 0.0722877648951469,\n      \"last-10-avg\": 0.0722877648951469\n    },\n    \"time_this_iter_s\": {\n      \"max\": 259.4514570236206,\n      \"min\": 259.4514570236206,\n      \"avg\": 259.4514570236206,\n      \"last\": 259.4514570236206,\n      \"last-5-avg\": 259.4514570236206,\n      \"last-10-avg\": 259.4514570236206\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 259.4514570236206,\n      \"min\": 259.4514570236206,\n      \"avg\": 259.4514570236206,\n      \"last\": 259.4514570236206,\n      \"last-5-avg\": 259.4514570236206,\n      \"last-10-avg\": 259.4514570236206\n    },\n    \"time_since_restore\": {\n      \"max\": 259.4514570236206,\n      \"min\": 259.4514570236206,\n      \"avg\": 259.4514570236206,\n      \"last\": 259.4514570236206,\n      \"last-5-avg\": 259.4514570236206,\n      \"last-10-avg\": 259.4514570236206\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.01539921760559082,\n      \"min\": 0.01539921760559082,\n      \"avg\": 0.01539921760559082,\n      \"last\": 0.01539921760559082,\n      \"last-5-avg\": 0.01539921760559082,\n      \"last-10-avg\": 0.01539921760559082\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308da2620727381b23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308da2620727381b23f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407037392b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407037392b000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407037392b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407037392b000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407037392b000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407037392b000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f8f89a000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f8f89a000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565753.448525,\n  \"relative_logdir\": \"objective_ca631938_2_colsample_bylevel=0.5414,colsample_bytree=0.5969,learning_rate=0.0642,max_depth=13,n_estimators=8163,reg_alph_2023-04-15_15-35-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"802a56aa\",\n  \"config\": {\n    \"learning_rate\": 0.00022170934779669246,\n    \"max_depth\": 5,\n    \"n_estimators\": 2039,\n    \"subsample\": 0.7631393265826367,\n    \"colsample_bytree\": 0.9764165379748939,\n    \"colsample_bylevel\": 0.7303985375914777,\n    \"reg_alpha\": 0.06609337754134892,\n    \"reg_lambda\": 0.9230343084542303\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.7303985375914777,\n    \"colsample_bytree\": 0.9764165379748939,\n    \"learning_rate\": 0.00022170934779669246,\n    \"max_depth\": 5,\n    \"n_estimators\": 2039,\n    \"reg_alpha\": 0.06609337754134892,\n    \"reg_lambda\": 0.9230343084542303,\n    \"subsample\": 0.7631393265826367\n  },\n  \"experiment_tag\": \"6_colsample_bylevel=0.7304,colsample_bytree=0.9764,learning_rate=0.0002,max_depth=5,n_estimators=2039,reg_alpha=0.0661,reg_lambda=0.9230,subsample=0.7631\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.32600459303428686,\n    \"time_this_iter_s\": 101.10731887817383,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"802a56aa\",\n    \"experiment_id\": \"69f822dfeb954ed5aa19055a6fb55b07\",\n    \"date\": \"2023-04-15_15-38-24\",\n    \"timestamp\": 1681565904,\n    \"time_total_s\": 101.10731887817383,\n    \"pid\": 18644,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.00022170934779669246,\n      \"max_depth\": 5,\n      \"n_estimators\": 2039,\n      \"subsample\": 0.7631393265826367,\n      \"colsample_bytree\": 0.9764165379748939,\n      \"colsample_bylevel\": 0.7303985375914777,\n      \"reg_alpha\": 0.06609337754134892,\n      \"reg_lambda\": 0.9230343084542303\n    },\n    \"time_since_restore\": 101.10731887817383,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0480194091796875,\n    \"experiment_tag\": \"6_colsample_bylevel=0.7304,colsample_bytree=0.9764,learning_rate=0.0002,max_depth=5,n_estimators=2039,reg_alpha=0.0661,reg_lambda=0.9230,subsample=0.7631\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565904.7884188,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.32600459303428686,\n      \"min\": 0.32600459303428686,\n      \"avg\": 0.32600459303428686,\n      \"last\": 0.32600459303428686,\n      \"last-5-avg\": 0.32600459303428686,\n      \"last-10-avg\": 0.32600459303428686\n    },\n    \"time_this_iter_s\": {\n      \"max\": 101.10731887817383,\n      \"min\": 101.10731887817383,\n      \"avg\": 101.10731887817383,\n      \"last\": 101.10731887817383,\n      \"last-5-avg\": 101.10731887817383,\n      \"last-10-avg\": 101.10731887817383\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 101.10731887817383,\n      \"min\": 101.10731887817383,\n      \"avg\": 101.10731887817383,\n      \"last\": 101.10731887817383,\n      \"last-5-avg\": 101.10731887817383,\n      \"last-10-avg\": 101.10731887817383\n    },\n    \"time_since_restore\": {\n      \"max\": 101.10731887817383,\n      \"min\": 101.10731887817383,\n      \"avg\": 101.10731887817383,\n      \"last\": 101.10731887817383,\n      \"last-5-avg\": 101.10731887817383,\n      \"last-10-avg\": 101.10731887817383\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0480194091796875,\n      \"min\": 0.0480194091796875,\n      \"avg\": 0.0480194091796875,\n      \"last\": 0.0480194091796875,\n      \"last-5-avg\": 0.0480194091796875,\n      \"last-10-avg\": 0.0480194091796875\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430832655b5e42ddd43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430832655b5e42ddd43f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405946de50000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405946de50000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405946de50000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405946de50000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405946de50000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405946de50000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fa8960000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fa8960000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565790.6503894,\n  \"relative_logdir\": \"objective_802a56aa_6_colsample_bylevel=0.7304,colsample_bytree=0.9764,learning_rate=0.0002,max_depth=5,n_estimators=2039,reg_alpha_2023-04-15_15-36-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"e2eaabe7\",\n  \"config\": {\n    \"learning_rate\": 0.5666138380215521,\n    \"max_depth\": 15,\n    \"n_estimators\": 3181,\n    \"subsample\": 0.9966427972223558,\n    \"colsample_bytree\": 0.9555155389896506,\n    \"colsample_bylevel\": 0.6094671526324091,\n    \"reg_alpha\": 0.04908478779227162,\n    \"reg_lambda\": 0.06446479835177199\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.6094671526324091,\n    \"colsample_bytree\": 0.9555155389896506,\n    \"learning_rate\": 0.5666138380215521,\n    \"max_depth\": 15,\n    \"n_estimators\": 3181,\n    \"reg_alpha\": 0.04908478779227162,\n    \"reg_lambda\": 0.06446479835177199,\n    \"subsample\": 0.9966427972223558\n  },\n  \"experiment_tag\": \"5_colsample_bylevel=0.6095,colsample_bytree=0.9555,learning_rate=0.5666,max_depth=15,n_estimators=3181,reg_alpha=0.0491,reg_lambda=0.0645,subsample=0.9966\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.08535401026535153,\n    \"time_this_iter_s\": 135.2198531627655,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"e2eaabe7\",\n    \"experiment_id\": \"acaa77faab5d40fc839ab14c5fd31574\",\n    \"date\": \"2023-04-15_15-38-41\",\n    \"timestamp\": 1681565921,\n    \"time_total_s\": 135.2198531627655,\n    \"pid\": 20920,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.5666138380215521,\n      \"max_depth\": 15,\n      \"n_estimators\": 3181,\n      \"subsample\": 0.9966427972223558,\n      \"colsample_bytree\": 0.9555155389896506,\n      \"colsample_bylevel\": 0.6094671526324091,\n      \"reg_alpha\": 0.04908478779227162,\n      \"reg_lambda\": 0.06446479835177199\n    },\n    \"time_since_restore\": 135.2198531627655,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.015820741653442383,\n    \"experiment_tag\": \"5_colsample_bylevel=0.6095,colsample_bytree=0.9555,learning_rate=0.5666,max_depth=15,n_estimators=3181,reg_alpha=0.0491,reg_lambda=0.0645,subsample=0.9966\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565922.0418186,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.08535401026535153,\n      \"min\": 0.08535401026535153,\n      \"avg\": 0.08535401026535153,\n      \"last\": 0.08535401026535153,\n      \"last-5-avg\": 0.08535401026535153,\n      \"last-10-avg\": 0.08535401026535153\n    },\n    \"time_this_iter_s\": {\n      \"max\": 135.2198531627655,\n      \"min\": 135.2198531627655,\n      \"avg\": 135.2198531627655,\n      \"last\": 135.2198531627655,\n      \"last-5-avg\": 135.2198531627655,\n      \"last-10-avg\": 135.2198531627655\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 135.2198531627655,\n      \"min\": 135.2198531627655,\n      \"avg\": 135.2198531627655,\n      \"last\": 135.2198531627655,\n      \"last-5-avg\": 135.2198531627655,\n      \"last-10-avg\": 135.2198531627655\n    },\n    \"time_since_restore\": {\n      \"max\": 135.2198531627655,\n      \"min\": 135.2198531627655,\n      \"avg\": 135.2198531627655,\n      \"last\": 135.2198531627655,\n      \"last-5-avg\": 135.2198531627655,\n      \"last-10-avg\": 135.2198531627655\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.015820741653442383,\n      \"min\": 0.015820741653442383,\n      \"avg\": 0.015820741653442383,\n      \"last\": 0.015820741653442383,\n      \"last-5-avg\": 0.015820741653442383,\n      \"last-10-avg\": 0.015820741653442383\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea10acaac2d9b53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea10acaac2d9b53f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060e70909800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060e70909800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060e70909800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060e70909800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474060e70909800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474060e70909800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f90335000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f90335000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565780.9059415,\n  \"relative_logdir\": \"objective_e2eaabe7_5_colsample_bylevel=0.6095,colsample_bytree=0.9555,learning_rate=0.5666,max_depth=15,n_estimators=3181,reg_alph_2023-04-15_15-36-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"ee584a15\",\n  \"config\": {\n    \"learning_rate\": 0.13467134790464272,\n    \"max_depth\": 3,\n    \"n_estimators\": 3289,\n    \"subsample\": 0.5608845941451004,\n    \"colsample_bytree\": 0.7741408459115449,\n    \"colsample_bylevel\": 0.818961819759384,\n    \"reg_alpha\": 2.494395303730623,\n    \"reg_lambda\": 3.0427048897619744\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.818961819759384,\n    \"colsample_bytree\": 0.7741408459115449,\n    \"learning_rate\": 0.13467134790464272,\n    \"max_depth\": 3,\n    \"n_estimators\": 3289,\n    \"reg_alpha\": 2.494395303730623,\n    \"reg_lambda\": 3.0427048897619744,\n    \"subsample\": 0.5608845941451004\n  },\n  \"experiment_tag\": \"4_colsample_bylevel=0.8190,colsample_bytree=0.7741,learning_rate=0.1347,max_depth=3,n_estimators=3289,reg_alpha=2.4944,reg_lambda=3.0427,subsample=0.5609\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.0847575878253202,\n    \"time_this_iter_s\": 119.96259355545044,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ee584a15\",\n    \"experiment_id\": \"49de73c6adde4dd7b30a097f38a74b48\",\n    \"date\": \"2023-04-15_15-38-17\",\n    \"timestamp\": 1681565897,\n    \"time_total_s\": 119.96259355545044,\n    \"pid\": 23908,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.13467134790464272,\n      \"max_depth\": 3,\n      \"n_estimators\": 3289,\n      \"subsample\": 0.5608845941451004,\n      \"colsample_bytree\": 0.7741408459115449,\n      \"colsample_bylevel\": 0.818961819759384,\n      \"reg_alpha\": 2.494395303730623,\n      \"reg_lambda\": 3.0427048897619744\n    },\n    \"time_since_restore\": 119.96259355545044,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.006520271301269531,\n    \"experiment_tag\": \"4_colsample_bylevel=0.8190,colsample_bytree=0.7741,learning_rate=0.1347,max_depth=3,n_estimators=3289,reg_alpha=2.4944,reg_lambda=3.0427,subsample=0.5609\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565897.7024364,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.0847575878253202,\n      \"min\": 0.0847575878253202,\n      \"avg\": 0.0847575878253202,\n      \"last\": 0.0847575878253202,\n      \"last-5-avg\": 0.0847575878253202,\n      \"last-10-avg\": 0.0847575878253202\n    },\n    \"time_this_iter_s\": {\n      \"max\": 119.96259355545044,\n      \"min\": 119.96259355545044,\n      \"avg\": 119.96259355545044,\n      \"last\": 119.96259355545044,\n      \"last-5-avg\": 119.96259355545044,\n      \"last-10-avg\": 119.96259355545044\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 119.96259355545044,\n      \"min\": 119.96259355545044,\n      \"avg\": 119.96259355545044,\n      \"last\": 119.96259355545044,\n      \"last-5-avg\": 119.96259355545044,\n      \"last-10-avg\": 119.96259355545044\n    },\n    \"time_since_restore\": {\n      \"max\": 119.96259355545044,\n      \"min\": 119.96259355545044,\n      \"avg\": 119.96259355545044,\n      \"last\": 119.96259355545044,\n      \"last-5-avg\": 119.96259355545044,\n      \"last-10-avg\": 119.96259355545044\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.006520271301269531,\n      \"min\": 0.006520271301269531,\n      \"avg\": 0.006520271301269531,\n      \"last\": 0.006520271301269531,\n      \"last-5-avg\": 0.006520271301269531,\n      \"last-10-avg\": 0.006520271301269531\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622fcc5bacb2b53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622fcc5bacb2b53f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405dfd9b22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405dfd9b22000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405dfd9b22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405dfd9b22000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405dfd9b22000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405dfd9b22000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7ab50000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7ab50000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565771.611544,\n  \"relative_logdir\": \"objective_ee584a15_4_colsample_bylevel=0.8190,colsample_bytree=0.7741,learning_rate=0.1347,max_depth=3,n_estimators=3289,reg_alpha_2023-04-15_15-36-11\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"94c09676\",\n  \"config\": {\n    \"learning_rate\": 0.13263308097339124,\n    \"max_depth\": 4,\n    \"n_estimators\": 2104,\n    \"subsample\": 0.5031310788722316,\n    \"colsample_bytree\": 0.9842015518664837,\n    \"colsample_bylevel\": 0.6747524214706248,\n    \"reg_alpha\": 14.783583245077118,\n    \"reg_lambda\": 0.11104447641348156\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.6747524214706248,\n    \"colsample_bytree\": 0.9842015518664837,\n    \"learning_rate\": 0.13263308097339124,\n    \"max_depth\": 4,\n    \"n_estimators\": 2104,\n    \"reg_alpha\": 14.783583245077118,\n    \"reg_lambda\": 0.11104447641348156,\n    \"subsample\": 0.5031310788722316\n  },\n  \"experiment_tag\": \"8_colsample_bylevel=0.6748,colsample_bytree=0.9842,learning_rate=0.1326,max_depth=4,n_estimators=2104,reg_alpha=14.7836,reg_lambda=0.1110,subsample=0.5031\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.37541906862340807,\n    \"time_this_iter_s\": 82.01640605926514,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"94c09676\",\n    \"experiment_id\": \"4a57e4b872974084ad1787331b1d56b9\",\n    \"date\": \"2023-04-15_15-39-26\",\n    \"timestamp\": 1681565966,\n    \"time_total_s\": 82.01640605926514,\n    \"pid\": 27196,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.13263308097339124,\n      \"max_depth\": 4,\n      \"n_estimators\": 2104,\n      \"subsample\": 0.5031310788722316,\n      \"colsample_bytree\": 0.9842015518664837,\n      \"colsample_bylevel\": 0.6747524214706248,\n      \"reg_alpha\": 14.783583245077118,\n      \"reg_lambda\": 0.11104447641348156\n    },\n    \"time_since_restore\": 82.01640605926514,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.04629921913146973,\n    \"experiment_tag\": \"8_colsample_bylevel=0.6748,colsample_bytree=0.9842,learning_rate=0.1326,max_depth=4,n_estimators=2104,reg_alpha=14.7836,reg_lambda=0.1110,subsample=0.5031\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565966.6481242,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.37541906862340807,\n      \"min\": 0.37541906862340807,\n      \"avg\": 0.37541906862340807,\n      \"last\": 0.37541906862340807,\n      \"last-5-avg\": 0.37541906862340807,\n      \"last-10-avg\": 0.37541906862340807\n    },\n    \"time_this_iter_s\": {\n      \"max\": 82.01640605926514,\n      \"min\": 82.01640605926514,\n      \"avg\": 82.01640605926514,\n      \"last\": 82.01640605926514,\n      \"last-5-avg\": 82.01640605926514,\n      \"last-10-avg\": 82.01640605926514\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 82.01640605926514,\n      \"min\": 82.01640605926514,\n      \"avg\": 82.01640605926514,\n      \"last\": 82.01640605926514,\n      \"last-5-avg\": 82.01640605926514,\n      \"last-10-avg\": 82.01640605926514\n    },\n    \"time_since_restore\": {\n      \"max\": 82.01640605926514,\n      \"min\": 82.01640605926514,\n      \"avg\": 82.01640605926514,\n      \"last\": 82.01640605926514,\n      \"last-5-avg\": 82.01640605926514,\n      \"last-10-avg\": 82.01640605926514\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.04629921913146973,\n      \"min\": 0.04629921913146973,\n      \"avg\": 0.04629921913146973,\n      \"last\": 0.04629921913146973,\n      \"last-5-avg\": 0.04629921913146973,\n      \"last-10-avg\": 0.04629921913146973\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087d1182b3dd06d83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087d1182b3dd06d83f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054810ccc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054810ccc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054810ccc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054810ccc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474054810ccc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474054810ccc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fa7b48800000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fa7b48800000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565841.8589323,\n  \"relative_logdir\": \"objective_94c09676_8_colsample_bylevel=0.6748,colsample_bytree=0.9842,learning_rate=0.1326,max_depth=4,n_estimators=2104,reg_alpha_2023-04-15_15-37-21\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"e736bb43\",\n  \"config\": {\n    \"learning_rate\": 0.005276476340287919,\n    \"max_depth\": 13,\n    \"n_estimators\": 205,\n    \"subsample\": 0.5870362242119296,\n    \"colsample_bytree\": 0.8321065338665687,\n    \"colsample_bylevel\": 0.5807534956034982,\n    \"reg_alpha\": 0.6634011600566797,\n    \"reg_lambda\": 1.8548554656783691\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.5807534956034982,\n    \"colsample_bytree\": 0.8321065338665687,\n    \"learning_rate\": 0.005276476340287919,\n    \"max_depth\": 13,\n    \"n_estimators\": 205,\n    \"reg_alpha\": 0.6634011600566797,\n    \"reg_lambda\": 1.8548554656783691,\n    \"subsample\": 0.5870362242119296\n  },\n  \"experiment_tag\": \"7_colsample_bylevel=0.5808,colsample_bytree=0.8321,learning_rate=0.0053,max_depth=13,n_estimators=205,reg_alpha=0.6634,reg_lambda=1.8549,subsample=0.5870\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.20190343522207407,\n    \"time_this_iter_s\": 11.620278120040894,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"e736bb43\",\n    \"experiment_id\": \"bd9ded2b105245faa8f101ab8275319a\",\n    \"date\": \"2023-04-15_15-37-28\",\n    \"timestamp\": 1681565848,\n    \"time_total_s\": 11.620278120040894,\n    \"pid\": 13560,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.005276476340287919,\n      \"max_depth\": 13,\n      \"n_estimators\": 205,\n      \"subsample\": 0.5870362242119296,\n      \"colsample_bytree\": 0.8321065338665687,\n      \"colsample_bylevel\": 0.5807534956034982,\n      \"reg_alpha\": 0.6634011600566797,\n      \"reg_lambda\": 1.8548554656783691\n    },\n    \"time_since_restore\": 11.620278120040894,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.26962924003601074,\n    \"experiment_tag\": \"7_colsample_bylevel=0.5808,colsample_bytree=0.8321,learning_rate=0.0053,max_depth=13,n_estimators=205,reg_alpha=0.6634,reg_lambda=1.8549,subsample=0.5870\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565889.7262886,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.20190343522207407,\n      \"min\": 0.20190343522207407,\n      \"avg\": 0.20190343522207407,\n      \"last\": 0.20190343522207407,\n      \"last-5-avg\": 0.20190343522207407,\n      \"last-10-avg\": 0.20190343522207407\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11.620278120040894,\n      \"min\": 11.620278120040894,\n      \"avg\": 11.620278120040894,\n      \"last\": 11.620278120040894,\n      \"last-5-avg\": 11.620278120040894,\n      \"last-10-avg\": 11.620278120040894\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 11.620278120040894,\n      \"min\": 11.620278120040894,\n      \"avg\": 11.620278120040894,\n      \"last\": 11.620278120040894,\n      \"last-5-avg\": 11.620278120040894,\n      \"last-10-avg\": 11.620278120040894\n    },\n    \"time_since_restore\": {\n      \"max\": 11.620278120040894,\n      \"min\": 11.620278120040894,\n      \"avg\": 11.620278120040894,\n      \"last\": 11.620278120040894,\n      \"last-5-avg\": 11.620278120040894,\n      \"last-10-avg\": 11.620278120040894\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.26962924003601074,\n      \"min\": 0.26962924003601074,\n      \"avg\": 0.26962924003601074,\n      \"last\": 0.26962924003601074,\n      \"last-5-avg\": 0.26962924003601074,\n      \"last-10-avg\": 0.26962924003601074\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085f4b9dc5f8d7c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085f4b9dc5f8d7c93f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740273d9518000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740273d9518000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740273d9518000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740273d9518000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740273d9518000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740273d9518000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd1419b00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd1419b00000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565809.2218356,\n  \"relative_logdir\": \"objective_e736bb43_7_colsample_bylevel=0.5808,colsample_bytree=0.8321,learning_rate=0.0053,max_depth=13,n_estimators=205,reg_alpha_2023-04-15_15-36-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"cfcc10d8\",\n  \"config\": {\n    \"learning_rate\": 0.7207284139903837,\n    \"max_depth\": 10,\n    \"n_estimators\": 1266,\n    \"subsample\": 0.7365175881018521,\n    \"colsample_bytree\": 0.7460978501753784,\n    \"colsample_bylevel\": 0.7103734927680118,\n    \"reg_alpha\": 3.853277855496492,\n    \"reg_lambda\": 13.6576086981688\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.7103734927680118,\n    \"colsample_bytree\": 0.7460978501753784,\n    \"learning_rate\": 0.7207284139903837,\n    \"max_depth\": 10,\n    \"n_estimators\": 1266,\n    \"reg_alpha\": 3.853277855496492,\n    \"reg_lambda\": 13.6576086981688,\n    \"subsample\": 0.7365175881018521\n  },\n  \"experiment_tag\": \"9_colsample_bylevel=0.7104,colsample_bytree=0.7461,learning_rate=0.7207,max_depth=10,n_estimators=1266,reg_alpha=3.8533,reg_lambda=13.6576,subsample=0.7365\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.09578617103141476,\n    \"time_this_iter_s\": 48.12621307373047,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"cfcc10d8\",\n    \"experiment_id\": \"bd9ded2b105245faa8f101ab8275319a\",\n    \"date\": \"2023-04-15_15-38-59\",\n    \"timestamp\": 1681565939,\n    \"time_total_s\": 48.12621307373047,\n    \"pid\": 13560,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.7207284139903837,\n      \"max_depth\": 10,\n      \"n_estimators\": 1266,\n      \"subsample\": 0.7365175881018521,\n      \"colsample_bytree\": 0.7460978501753784,\n      \"colsample_bylevel\": 0.7103734927680118,\n      \"reg_alpha\": 3.853277855496492,\n      \"reg_lambda\": 13.6576086981688\n    },\n    \"time_since_restore\": 48.12621307373047,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.26962924003601074,\n    \"experiment_tag\": \"9_colsample_bylevel=0.7104,colsample_bytree=0.7461,learning_rate=0.7207,max_depth=10,n_estimators=1266,reg_alpha=3.8533,reg_lambda=13.6576,subsample=0.7365\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681565939.79867,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.09578617103141476,\n      \"min\": 0.09578617103141476,\n      \"avg\": 0.09578617103141476,\n      \"last\": 0.09578617103141476,\n      \"last-5-avg\": 0.09578617103141476,\n      \"last-10-avg\": 0.09578617103141476\n    },\n    \"time_this_iter_s\": {\n      \"max\": 48.12621307373047,\n      \"min\": 48.12621307373047,\n      \"avg\": 48.12621307373047,\n      \"last\": 48.12621307373047,\n      \"last-5-avg\": 48.12621307373047,\n      \"last-10-avg\": 48.12621307373047\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 48.12621307373047,\n      \"min\": 48.12621307373047,\n      \"avg\": 48.12621307373047,\n      \"last\": 48.12621307373047,\n      \"last-5-avg\": 48.12621307373047,\n      \"last-10-avg\": 48.12621307373047\n    },\n    \"time_since_restore\": {\n      \"max\": 48.12621307373047,\n      \"min\": 48.12621307373047,\n      \"avg\": 48.12621307373047,\n      \"last\": 48.12621307373047,\n      \"last-5-avg\": 48.12621307373047,\n      \"last-10-avg\": 48.12621307373047\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.26962924003601074,\n      \"min\": 0.26962924003601074,\n      \"avg\": 0.26962924003601074,\n      \"last\": 0.26962924003601074,\n      \"last-5-avg\": 0.26962924003601074,\n      \"last-10-avg\": 0.26962924003601074\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622efd477185b83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622efd477185b83f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740481027c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740481027c0000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740481027c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740481027c0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740481027c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740481027c0000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd1419b00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd1419b00000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565891.6298022,\n  \"relative_logdir\": \"objective_cfcc10d8_9_colsample_bylevel=0.7104,colsample_bytree=0.7461,learning_rate=0.7207,max_depth=10,n_estimators=1266,reg_alph_2023-04-15_15-38-11\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"1621e9ec\",\n  \"config\": {\n    \"learning_rate\": 0.004964809234049963,\n    \"max_depth\": 10,\n    \"n_estimators\": 6742,\n    \"subsample\": 0.8263281233668444,\n    \"colsample_bytree\": 0.8595347958201262,\n    \"colsample_bylevel\": 0.979621849323453,\n    \"reg_alpha\": 0.6766630370620083,\n    \"reg_lambda\": 0.8611433557840324\n  },\n  \"_local_dir\": \"C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\ml_prediction\\\\ray_results\\\\xgboost_tuning\",\n  \"evaluated_params\": {\n    \"colsample_bylevel\": 0.979621849323453,\n    \"colsample_bytree\": 0.8595347958201262,\n    \"learning_rate\": 0.004964809234049963,\n    \"max_depth\": 10,\n    \"n_estimators\": 6742,\n    \"reg_alpha\": 0.6766630370620083,\n    \"reg_lambda\": 0.8611433557840324,\n    \"subsample\": 0.8263281233668444\n  },\n  \"experiment_tag\": \"10_colsample_bylevel=0.9796,colsample_bytree=0.8595,learning_rate=0.0050,max_depth=10,n_estimators=6742,reg_alpha=0.6767,reg_lambda=0.8611,subsample=0.8263\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"rmse\": 0.07838868851053801,\n    \"time_this_iter_s\": 271.225914478302,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"1621e9ec\",\n    \"experiment_id\": \"49de73c6adde4dd7b30a097f38a74b48\",\n    \"date\": \"2023-04-15_15-42-49\",\n    \"timestamp\": 1681566169,\n    \"time_total_s\": 271.225914478302,\n    \"pid\": 23908,\n    \"hostname\": \"Manu-Lenovo-X1\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"learning_rate\": 0.004964809234049963,\n      \"max_depth\": 10,\n      \"n_estimators\": 6742,\n      \"subsample\": 0.8263281233668444,\n      \"colsample_bytree\": 0.8595347958201262,\n      \"colsample_bylevel\": 0.979621849323453,\n      \"reg_alpha\": 0.6766630370620083,\n      \"reg_lambda\": 0.8611433557840324\n    },\n    \"time_since_restore\": 271.225914478302,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.006520271301269531,\n    \"experiment_tag\": \"10_colsample_bylevel=0.9796,colsample_bytree=0.8595,learning_rate=0.0050,max_depth=10,n_estimators=6742,reg_alpha=0.6767,reg_lambda=0.8611,subsample=0.8263\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1681566169.2501507,\n  \"metric_analysis\": {\n    \"rmse\": {\n      \"max\": 0.07838868851053801,\n      \"min\": 0.07838868851053801,\n      \"avg\": 0.07838868851053801,\n      \"last\": 0.07838868851053801,\n      \"last-5-avg\": 0.07838868851053801,\n      \"last-10-avg\": 0.07838868851053801\n    },\n    \"time_this_iter_s\": {\n      \"max\": 271.225914478302,\n      \"min\": 271.225914478302,\n      \"avg\": 271.225914478302,\n      \"last\": 271.225914478302,\n      \"last-5-avg\": 271.225914478302,\n      \"last-10-avg\": 271.225914478302\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 271.225914478302,\n      \"min\": 271.225914478302,\n      \"avg\": 271.225914478302,\n      \"last\": 271.225914478302,\n      \"last-5-avg\": 271.225914478302,\n      \"last-10-avg\": 271.225914478302\n    },\n    \"time_since_restore\": {\n      \"max\": 271.225914478302,\n      \"min\": 271.225914478302,\n      \"avg\": 271.225914478302,\n      \"last\": 271.225914478302,\n      \"last-5-avg\": 271.225914478302,\n      \"last-10-avg\": 271.225914478302\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.006520271301269531,\n      \"min\": 0.006520271301269531,\n      \"avg\": 0.006520271301269531,\n      \"last\": 0.006520271301269531,\n      \"last-5-avg\": 0.006520271301269531,\n      \"last-10-avg\": 0.006520271301269531\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rmse\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088e7287f54711b43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088e7287f54711b43f9486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474070f39d58800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474070f39d58800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474070f39d58800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474070f39d58800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474070f39d58800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474070f39d58800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7ab50000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7ab50000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1681565897.9302433,\n  \"relative_logdir\": \"objective_1621e9ec_10_colsample_bylevel=0.9796,colsample_bytree=0.8595,learning_rate=0.0050,max_depth=10,n_estimators=6742,reg_alp_2023-04-15_15-38-17\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"xgboost_tuning\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 1,
    "_metric": "rmse",
    "_total_time": 2930.4108209609985,
    "_iteration": 73,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1681565738.7437174,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-04-15_15-35-38",
    "checkpoint_file": "C:\\Users\\manue\\switchdrive\\Mutual Funds Project\\ml_prediction\\ray_results\\xgboost_tuning\\experiment_state-2023-04-15_15-35-38.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1681565738.7437174,
    "timestamp": 1681566164.2477546
  }
}