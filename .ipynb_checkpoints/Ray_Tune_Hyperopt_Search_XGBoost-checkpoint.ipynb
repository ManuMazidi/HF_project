{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a7b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 10:15:04,889\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(object_store_memory=4000000000) # set object store memory to 4GB\n",
    "\n",
    "data = pd.read_pickle('C:\\\\Users\\\\manue\\\\switchdrive\\\\Mutual Funds Project\\\\data\\\\pickle_files\\\\full_dataset.pkl')\n",
    "sample = data.sample(101, random_state=1)\n",
    "\n",
    "# tansform 'Rating' from Categorical to float\n",
    "import numpy as np\n",
    "sample[\"Rating\"] = pd.to_numeric(sample[\"Rating\"], errors='coerce')\n",
    "\n",
    "# drop all rows with inf/-inf values!\n",
    "import numpy as np\n",
    "sample = sample[(sample != np.inf).all(axis=1)]\n",
    "sample = sample[(sample != -np.inf).all(axis=1)]\n",
    "\n",
    "#get rid of whitespace to draw tree later\n",
    "Eq_Stylebox = sample['Eq_Stylebox_Long'].astype('object').replace(' ','_', regex=True)\n",
    "sample['Eq_Stylebox_Long'] = Eq_Stylebox.astype('category')\n",
    "\n",
    "# shifting target variable to predict next month\n",
    "sample['returns'] = sample.returns.shift(-1)\n",
    "sample = sample.drop(sample.tail(1).index)\n",
    "\n",
    "\n",
    "X = sample.drop('returns', axis=1)\n",
    "y = sample['returns']\n",
    "\n",
    "# create dummies in case of categorical data\n",
    "dummy_needed = [#'Rating',\n",
    "                'Financial_Health_Grade_Long',\n",
    "                 'Growth_Grade_Long',\n",
    "                 'Profitability_Grade_Long',\n",
    "                 'Eq_Stylebox_Long']\n",
    "\n",
    "X = pd.get_dummies(X, columns=dummy_needed)\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 26)\n",
    "#X_train = ray.put(X_train)\n",
    "#y_train = ray.put(y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44e61077",
   "metadata": {},
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.0001), np.log(0.9)),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", range(1, 16)),\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", range(100, 10000)),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"colsample_bylevel\": hp.uniform(\"colsample_bylevel\", 0.5, 1),\n",
    "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(100)),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(100)),\n",
    "}\n",
    "\n",
    "\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=26)\n",
    "\n",
    "# Define the objective function to optimize\n",
    "def objective(config):\n",
    "    model = xgb.XGBRegressor(**config, n_jobs=-1)\n",
    "    score = cross_val_score(model, X=ray.get(X_train), y=ray.get(y_train), scoring=\"neg_mean_squared_error\", cv=kfolds)\n",
    "    rmse = np.sqrt(-np.mean(score))\n",
    "    tune.report(rmse=rmse)\n",
    "\n",
    "# Define the search algorithm\n",
    "search_alg = HyperOptSearch(space=search_space, metric=\"rmse\", mode=\"min\")\n",
    "# to limit number of cores, uncomment and set max_concurrent \n",
    "# algo = ConcurrencyLimiter(algo, max_concurrent=10)\n",
    "scheduler = AsyncHyperBandScheduler()\n",
    "\n",
    "# Define the hyperparameter tuning trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Define the configuration for Ray Tune\n",
    "config = {\n",
    "    'num_samples': 10,\n",
    "    'config': search_space,\n",
    "    'search_alg': search_alg,\n",
    "    'scheduler': scheduler,\n",
    "    'resources_per_trial': {'cpu': 1},\n",
    "    'metric': 'rmse',\n",
    "    'mode': 'min',\n",
    "    'verbose': 1,\n",
    "    'name': 'xgboost_tuning',\n",
    "    'stop': {'training_iteration': 10},\n",
    "    'local_dir': './ray_results',\n",
    "}\n",
    "\n",
    "# Start the hyperparameter tuning using Ray Tune\n",
    "analysis = tune.run(objective, **config)\n",
    "\n",
    "# Print the best hyperparameters found during the search\n",
    "best_params = analysis.get_best_config(metric='rmse')\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8254b",
   "metadata": {},
   "source": [
    "### RAY XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb59ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-14 10:21:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:37.98        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.21 GiB heap, 0.0/3.73 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_xgboost_562f1_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-21-20\\train_xgboost_562f1_00000_0_colsample_bylevel=0.9013,colsample_bytree=0.8510,learning_rate=0.0044,max_depth=2,n_estimators=8413,re_2023-04-14_10-21-21\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00001</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-21-20\\train_xgboost_562f1_00001_1_colsample_bylevel=0.9070,colsample_bytree=0.9332,learning_rate=0.0002,max_depth=1,n_estimators=769,reg_2023-04-14_10-21-28\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00002</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-21-20\\train_xgboost_562f1_00002_2_colsample_bylevel=0.9665,colsample_bytree=0.8353,learning_rate=0.0006,max_depth=12,n_estimators=7117,r_2023-04-14_10-21-35\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00003</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-21-20\\train_xgboost_562f1_00003_3_colsample_bylevel=0.8377,colsample_bytree=0.9315,learning_rate=0.0010,max_depth=8,n_estimators=3157,re_2023-04-14_10-21-42\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00004</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-21-20\\train_xgboost_562f1_00004_4_colsample_bylevel=0.8678,colsample_bytree=0.8076,learning_rate=0.3912,max_depth=6,n_estimators=3126,re_2023-04-14_10-21-51\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_xgboost_562f1_00000</td><td>ERROR   </td><td>127.0.0.1:6620 </td><td style=\"text-align: right;\">           0.901319</td><td style=\"text-align: right;\">          0.851022</td><td style=\"text-align: right;\">    0.00442476 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">          8413</td><td style=\"text-align: right;\">  1.89589  </td><td style=\"text-align: right;\">   0.195596 </td><td style=\"text-align: right;\">   0.996528</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00001</td><td>ERROR   </td><td>127.0.0.1:13820</td><td style=\"text-align: right;\">           0.907044</td><td style=\"text-align: right;\">          0.933161</td><td style=\"text-align: right;\">    0.000193128</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">           769</td><td style=\"text-align: right;\">  1.59141  </td><td style=\"text-align: right;\">   1.14684  </td><td style=\"text-align: right;\">   0.900767</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00002</td><td>ERROR   </td><td>127.0.0.1:22220</td><td style=\"text-align: right;\">           0.966529</td><td style=\"text-align: right;\">          0.835264</td><td style=\"text-align: right;\">    0.000595643</td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">          7117</td><td style=\"text-align: right;\">  0.15912  </td><td style=\"text-align: right;\">   3.72587  </td><td style=\"text-align: right;\">   0.96752 </td></tr>\n",
       "<tr><td>train_xgboost_562f1_00003</td><td>ERROR   </td><td>127.0.0.1:23936</td><td style=\"text-align: right;\">           0.83766 </td><td style=\"text-align: right;\">          0.931536</td><td style=\"text-align: right;\">    0.00102074 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">          3157</td><td style=\"text-align: right;\">  0.0200599</td><td style=\"text-align: right;\">   0.0607533</td><td style=\"text-align: right;\">   0.981355</td></tr>\n",
       "<tr><td>train_xgboost_562f1_00004</td><td>ERROR   </td><td>127.0.0.1:23528</td><td style=\"text-align: right;\">           0.867784</td><td style=\"text-align: right;\">          0.807554</td><td style=\"text-align: right;\">    0.39121    </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          3126</td><td style=\"text-align: right;\">  0.0118646</td><td style=\"text-align: right;\">   0.0033219</td><td style=\"text-align: right;\">   0.801839</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 10:21:27,887\tERROR trial_runner.py:1062 -- Trial train_xgboost_562f1_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6620, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:21:35,108\tERROR trial_runner.py:1062 -- Trial train_xgboost_562f1_00001: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=13820, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:21:41,878\tERROR trial_runner.py:1062 -- Trial train_xgboost_562f1_00002: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=22220, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:21:51,427\tERROR trial_runner.py:1062 -- Trial train_xgboost_562f1_00003: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23936, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:21:58,752\tERROR trial_runner.py:1062 -- Trial train_xgboost_562f1_00004: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23528, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_xgboost_562f1_00000, train_xgboost_562f1_00001, train_xgboost_562f1_00002, train_xgboost_562f1_00003, train_xgboost_562f1_00004])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19432\\1432586595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m analysis = tune.run(tune.with_parameters(train_xgboost, ray_params = ray_params),\n\u001b[0m\u001b[0;32m     69\u001b[0m                     \u001b[0mresources_per_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mray_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tune_resources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_xgboost_562f1_00000, train_xgboost_562f1_00001, train_xgboost_562f1_00002, train_xgboost_562f1_00003, train_xgboost_562f1_00004])"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from ray import tune\n",
    "\n",
    "def train_xgboost(config, checkpoint_dir=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_set = RayDMatrix(X_train, y_train)\n",
    "    test_set = RayDMatrix(X_test, y_test)\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    # train the model\n",
    "    bst = train(\n",
    "        params=config,\n",
    "        dtrain=train_set,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(test_set, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "        num_boost_round=5, #equivalent to 'epochs'\n",
    "        ray_params=RayParams(num_actors=4, cpus_per_actor=2)) #parameters for parallelism\n",
    "    \n",
    "    model_path = 'model.xgb'\n",
    "    bst.save_model(model_path)\n",
    "    print(f'total time taken: {time.time()-start_time}')\n",
    "    print('Final rmse: {:.4f}'.format(\n",
    "    evals_result[\"eval\"][\"rmse\"][-1]))\n",
    "    \n",
    "    return bst\n",
    "    \n",
    "\n",
    "# Define the search algorithm and scheduler\n",
    "#### NOT SURE IF NEEDED OR SUPPORTED IN XGB_RAY! maybe uncomment here and in config\n",
    "search_alg = HyperOptSearch()\n",
    "scheduler = ASHAScheduler(max_t=10, grace_period=1)\n",
    "\n",
    "# Specify the hyperparameter search space.\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"reg:squarederror\", # Use regression objective\n",
    "    \"eval_metric\": \"rmse\", # Set the evaluation metric to RMSE\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 0.9),\n",
    "    \"subsample\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bytree\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bylevel\": tune.uniform(0.8, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 16),\n",
    "    \"n_estimators\": tune.randint(500, 10000),\n",
    "    \"reg_alpha\": tune.loguniform(1e-3, 100),\n",
    "    \"reg_lambda\": tune.loguniform(1e-3, 100),\n",
    "}\n",
    "\n",
    "# Run the hyperparameter search\n",
    "analysis = tune.run(\n",
    "    train_xgboost,\n",
    "    resources_per_trial=RayParams(num_actors=4, cpus_per_actor=2).get_tune_resources(),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    search_alg=search_alg,\n",
    "    scheduler=scheduler,\n",
    "    metric='rmse',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_RMSE = analysis.best_result[\"rmse\"]\n",
    "print(f'Best model parameters: {analysis.best_config}')\n",
    "print(f'Best RMSE: {best_RMSE}')\n",
    "print(analysis.best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f07a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-14 10:37:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:35.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.21 GiB heap, 0.0/3.73 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_xgboost_a15b1406</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-36-32\\train_xgboost_a15b1406_1_colsample_bylevel=0.9488,colsample_bytree=0.9470,eval_metric=rmse,learning_rate=0.0001,max_depth=5,n_esti_2023-04-14_10-36-32\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_25cc6eb8</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-36-32\\train_xgboost_25cc6eb8_2_colsample_bylevel=0.9566,colsample_bytree=0.9258,eval_metric=rmse,learning_rate=0.0001,max_depth=10,n_est_2023-04-14_10-36-39\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_1e1be016</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-36-32\\train_xgboost_1e1be016_3_colsample_bylevel=0.8457,colsample_bytree=0.9737,eval_metric=rmse,learning_rate=0.4618,max_depth=6,n_esti_2023-04-14_10-36-46\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_90f27f23</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-36-32\\train_xgboost_90f27f23_4_colsample_bylevel=0.8301,colsample_bytree=0.8863,eval_metric=rmse,learning_rate=0.0002,max_depth=6,n_esti_2023-04-14_10-36-53\\error.txt</td></tr>\n",
       "<tr><td>train_xgboost_9736a753</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\manue\\ray_results\\train_xgboost_2023-04-14_10-36-32\\train_xgboost_9736a753_5_colsample_bylevel=0.9963,colsample_bytree=0.9813,eval_metric=rmse,learning_rate=0.0001,max_depth=8,n_esti_2023-04-14_10-37-00\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th>eval_metric  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  n_estimators</th><th>objective       </th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th>tree_method  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_xgboost_a15b1406</td><td>ERROR   </td><td>127.0.0.1:20784</td><td style=\"text-align: right;\">           0.94884 </td><td style=\"text-align: right;\">          0.946966</td><td>rmse         </td><td style=\"text-align: right;\">    0.000109442</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          5072</td><td>reg:squarederror</td><td style=\"text-align: right;\"> 0.0607008 </td><td style=\"text-align: right;\">  0.00669629</td><td style=\"text-align: right;\">   0.843768</td><td>approx       </td></tr>\n",
       "<tr><td>train_xgboost_25cc6eb8</td><td>ERROR   </td><td>127.0.0.1:2008 </td><td style=\"text-align: right;\">           0.956606</td><td style=\"text-align: right;\">          0.925815</td><td>rmse         </td><td style=\"text-align: right;\">    0.000107152</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">          1949</td><td>reg:squarederror</td><td style=\"text-align: right;\"> 0.00177046</td><td style=\"text-align: right;\"> 17.4187    </td><td style=\"text-align: right;\">   0.832601</td><td>approx       </td></tr>\n",
       "<tr><td>train_xgboost_1e1be016</td><td>ERROR   </td><td>127.0.0.1:12052</td><td style=\"text-align: right;\">           0.845655</td><td style=\"text-align: right;\">          0.973687</td><td>rmse         </td><td style=\"text-align: right;\">    0.461771   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          9242</td><td>reg:squarederror</td><td style=\"text-align: right;\"> 0.00468475</td><td style=\"text-align: right;\">  0.123334  </td><td style=\"text-align: right;\">   0.950859</td><td>approx       </td></tr>\n",
       "<tr><td>train_xgboost_90f27f23</td><td>ERROR   </td><td>127.0.0.1:11988</td><td style=\"text-align: right;\">           0.830128</td><td style=\"text-align: right;\">          0.886264</td><td>rmse         </td><td style=\"text-align: right;\">    0.00020366 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          7333</td><td>reg:squarederror</td><td style=\"text-align: right;\"> 1.35574   </td><td style=\"text-align: right;\">  1.22889   </td><td style=\"text-align: right;\">   0.823849</td><td>approx       </td></tr>\n",
       "<tr><td>train_xgboost_9736a753</td><td>ERROR   </td><td>127.0.0.1:21772</td><td style=\"text-align: right;\">           0.996313</td><td style=\"text-align: right;\">          0.981318</td><td>rmse         </td><td style=\"text-align: right;\">    0.000146827</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">          2578</td><td>reg:squarederror</td><td style=\"text-align: right;\"> 0.00161149</td><td style=\"text-align: right;\"> 24.9543    </td><td style=\"text-align: right;\">   0.892406</td><td>approx       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 10:36:39,286\tERROR trial_runner.py:1062 -- Trial train_xgboost_a15b1406: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=20784, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:36:46,565\tERROR trial_runner.py:1062 -- Trial train_xgboost_25cc6eb8: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2008, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:36:53,340\tERROR trial_runner.py:1062 -- Trial train_xgboost_1e1be016: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=12052, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:37:00,788\tERROR trial_runner.py:1062 -- Trial train_xgboost_90f27f23: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=11988, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n",
      "2023-04-14 10:37:08,300\tERROR trial_runner.py:1062 -- Trial train_xgboost_9736a753: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=21772, ip=127.0.0.1, repr=train_xgboost)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 803, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\manue\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\", line 16, in train_xgboost\n",
      "  File \"C:\\Users\\manue\\anaconda3\\lib\\site-packages\\xgboost_ray\\main.py\", line 1295, in train\n",
      "    raise RuntimeError(\"xgboost-ray training currently does not support \"\n",
      "RuntimeError: xgboost-ray training currently does not support Windows.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_xgboost_a15b1406, train_xgboost_25cc6eb8, train_xgboost_1e1be016, train_xgboost_90f27f23, train_xgboost_9736a753])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19432\\4230180470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Run the hyperparameter search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m analysis = tune.run(\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mtrain_xgboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mresources_per_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRayParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_actors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpus_per_actor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tune_resources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_xgboost_a15b1406, train_xgboost_25cc6eb8, train_xgboost_1e1be016, train_xgboost_90f27f23, train_xgboost_9736a753])"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from ray import tune\n",
    "\n",
    "def train_xgboost(config, checkpoint_dir=None):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_set = RayDMatrix(X_train, y_train)\n",
    "    test_set = RayDMatrix(X_test, y_test)\n",
    "    \n",
    "    evals_result = {}\n",
    "    \n",
    "    # train the model\n",
    "    bst = train(\n",
    "        params=config,\n",
    "        dtrain=train_set,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(test_set, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "        num_boost_round=5, #equivalent to 'epochs'\n",
    "        ray_params=RayParams(num_actors=4, cpus_per_actor=2)) #parameters for parallelism\n",
    "    \n",
    "    model_path = 'model.xgb'\n",
    "    bst.save_model(model_path)\n",
    "    print(f'total time taken: {time.time()-start_time}')\n",
    "    print('Final rmse: {:.4f}'.format(\n",
    "    evals_result[\"eval\"][\"rmse\"][-1]))\n",
    "    \n",
    "    return bst\n",
    "    \n",
    "\n",
    "# Define the search algorithm and scheduler\n",
    "search_alg = HyperOptSearch()\n",
    "scheduler = ASHAScheduler(max_t=10, grace_period=1)\n",
    "\n",
    "# Specify the hyperparameter search space.\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"reg:squarederror\", # Use regression objective\n",
    "    \"eval_metric\": \"rmse\", # Set the evaluation metric to RMSE\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 0.9),\n",
    "    \"subsample\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bytree\": tune.uniform(0.8, 1.0),\n",
    "    \"colsample_bylevel\": tune.uniform(0.8, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 16),\n",
    "    \"n_estimators\": tune.randint(500, 10000),\n",
    "    \"reg_alpha\": tune.loguniform(1e-3, 100),\n",
    "    \"reg_lambda\": tune.loguniform(1e-3, 100),\n",
    "}\n",
    "\n",
    "# Run the hyperparameter search\n",
    "analysis = tune.run(\n",
    "    train_xgboost,\n",
    "    resources_per_trial=RayParams(num_actors=4, cpus_per_actor=2).get_tune_resources(),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    search_alg=search_alg,\n",
    "    scheduler=scheduler,\n",
    "    metric='rmse',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_RMSE = analysis.best_result[\"rmse\"]\n",
    "print(f'Best model parameters: {analysis.best_config}')\n",
    "print(f'Best RMSE: {best_RMSE}')\n",
    "print(analysis.best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
